## Домашнее задание 46 PostgreSQL Replication & Backup  
#### Цель домашнего задания  
Научиться настраивать репликацию и создавать резервные копии в СУБД PostgreSQL  

#### Описание домашнего задания  
1. Настроить hot_standby репликацию с использованием слотов  
2. Настроить правильное резервное копирование  

## Настройка репликации  
1. Исправляем явные ляпы методички  
    - пользователь replicator в hba вдруг именуется replication  
    - в конфиг-файле PostgreSQL не указан каталог данных кластера main  
+ После этого репликация запускается:  
```
Bringing machine 'node1' up with 'virtualbox' provider...
Bringing machine 'node2' up with 'virtualbox' provider...
Bringing machine 'barman' up with 'virtualbox' provider...
==> node1: Checking if box 'ubuntu/jammy64' version '20241002.0.0' is up to date...
==> node1: Clearing any previously set forwarded ports...
==> node1: Clearing any previously set network interfaces...
==> node1: Preparing network interfaces based on configuration...
    node1: Adapter 1: nat
    node1: Adapter 2: hostonly
==> node1: Forwarding ports...
    node1: 22 (guest) => 2222 (host) (adapter 1)
==> node1: Running 'pre-boot' VM customizations...
==> node1: Booting VM...
==> node1: Waiting for machine to boot. This may take a few minutes...
    node1: SSH address: 127.0.0.1:2222
    node1: SSH username: vagrant
    node1: SSH auth method: private key
    node1: Warning: Connection reset. Retrying...
    node1: Warning: Remote connection disconnect. Retrying...
==> node1: Machine booted and ready!
==> node1: Checking for guest additions in VM...
    node1: The guest additions on this VM do not match the installed version of
    node1: VirtualBox! In most cases this is fine, but in rare cases it can
    node1: prevent things such as shared folders from working properly. If you see
    node1: shared folder errors, please make sure the guest additions within the
    node1: virtual machine match the version of VirtualBox you have installed on
    node1: your host and reload your VM.
    node1: 
    node1: Guest Additions Version: 6.0.0 r127566
    node1: VirtualBox Version: 7.2
==> node1: Setting hostname...
==> node1: Configuring and enabling network interfaces...
==> node1: Mounting shared folders...
    node1: /home/user/otus/hw-46 => /vagrant
==> node1: Machine already provisioned. Run `vagrant provision` or use the `--provision`
==> node1: flag to force provisioning. Provisioners marked to run always will still run.
==> node2: Checking if box 'ubuntu/jammy64' version '20241002.0.0' is up to date...
==> node2: Clearing any previously set forwarded ports...
==> node2: Fixed port collision for 22 => 2222. Now on port 2200.
==> node2: Clearing any previously set network interfaces...
==> node2: Preparing network interfaces based on configuration...
    node2: Adapter 1: nat
    node2: Adapter 2: hostonly
==> node2: Forwarding ports...
    node2: 22 (guest) => 2200 (host) (adapter 1)
==> node2: Running 'pre-boot' VM customizations...
==> node2: Booting VM...
==> node2: Waiting for machine to boot. This may take a few minutes...
    node2: SSH address: 127.0.0.1:2200
    node2: SSH username: vagrant
    node2: SSH auth method: private key
    node2: Warning: Connection reset. Retrying...
    node2: Warning: Remote connection disconnect. Retrying...
==> node2: Machine booted and ready!
==> node2: Checking for guest additions in VM...
    node2: The guest additions on this VM do not match the installed version of
    node2: VirtualBox! In most cases this is fine, but in rare cases it can
    node2: prevent things such as shared folders from working properly. If you see
    node2: shared folder errors, please make sure the guest additions within the
    node2: virtual machine match the version of VirtualBox you have installed on
    node2: your host and reload your VM.
    node2: 
    node2: Guest Additions Version: 6.0.0 r127566
    node2: VirtualBox Version: 7.2
==> node2: Setting hostname...
==> node2: Configuring and enabling network interfaces...
==> node2: Mounting shared folders...
    node2: /home/user/otus/hw-46 => /vagrant
==> node2: Machine already provisioned. Run `vagrant provision` or use the `--provision`
==> node2: flag to force provisioning. Provisioners marked to run always will still run.
==> barman: Checking if box 'ubuntu/jammy64' version '20241002.0.0' is up to date...
==> barman: Clearing any previously set forwarded ports...
==> barman: Fixed port collision for 22 => 2222. Now on port 2201.
==> barman: Clearing any previously set network interfaces...
==> barman: Preparing network interfaces based on configuration...
    barman: Adapter 1: nat
    barman: Adapter 2: hostonly
==> barman: Forwarding ports...
    barman: 22 (guest) => 2201 (host) (adapter 1)
==> barman: Running 'pre-boot' VM customizations...
==> barman: Booting VM...
==> barman: Waiting for machine to boot. This may take a few minutes...
    barman: SSH address: 127.0.0.1:2201
    barman: SSH username: vagrant
    barman: SSH auth method: private key
    barman: Warning: Connection reset. Retrying...
    barman: Warning: Remote connection disconnect. Retrying...
==> barman: Machine booted and ready!
==> barman: Checking for guest additions in VM...
    barman: The guest additions on this VM do not match the installed version of
    barman: VirtualBox! In most cases this is fine, but in rare cases it can
    barman: prevent things such as shared folders from working properly. If you see
    barman: shared folder errors, please make sure the guest additions within the
    barman: virtual machine match the version of VirtualBox you have installed on
    barman: your host and reload your VM.
    barman: 
    barman: Guest Additions Version: 6.0.0 r127566
    barman: VirtualBox Version: 7.2
==> barman: Setting hostname...
==> barman: Configuring and enabling network interfaces...
==> barman: Mounting shared folders...
    barman: /home/user/otus/hw-46 => /vagrant
==> barman: Machine already provisioned. Run `vagrant provision` or use the `--provision`
==> barman: flag to force provisioning. Provisioners marked to run always will still run.
user@u22ws:~/otus/hw-46$ 

```
+ Указываем в hosts-файле пути к ключам, поскольку они индивидульны для каждой машины, а общие переменные складываем в ansible/group_vars/servers.yml
+ Запускаем ansible-playbook provision.yml
```  
user@u22ws:~/otus/hw-46/ansible$ ansible-playbook provision.yml -i hosts

PLAY [Postgres] ************************************************************************************************************************************************************************

TASK [Gathering Facts] *****************************************************************************************************************************************************************
ok: [barman]
ok: [node1]
ok: [node2]

PLAY [install postgres 14 and set up replication] **************************************************************************************************************************************

TASK [Gathering Facts] *****************************************************************************************************************************************************************
ok: [node1]
ok: [node2]

TASK [install_postgres : install postgresql-server 14] *********************************************************************************************************************************
ok: [node2]
ok: [node1]

TASK [install_postgres : enable and start service] *************************************************************************************************************************************
ok: [node2]
ok: [node1]

TASK [postgres_replication : Создать пользователя для физической репликации] ***********************************************************************************************************
skipping: [node2]
ok: [node1]

TASK [postgres_replication : Разрешить подключения для репликации в pg_hba.conf] *******************************************************************************************************
changed: [node1]
changed: [node2]

TASK [postgres_replication : stop postgresql-server on node2] **************************************************************************************************************************
skipping: [node1]
changed: [node2]

TASK [postgres_replication : copy postgresql.conf] *************************************************************************************************************************************
skipping: [node2]
ok: [node1]

TASK [postgres_replication : copy pg_hba.conf] *****************************************************************************************************************************************
skipping: [node2]
changed: [node1]

TASK [postgres_replication : restart postgresql-server on node1] ***********************************************************************************************************************
skipping: [node2]
changed: [node1]

TASK [postgres_replication : Remove files from data catalog] ***************************************************************************************************************************
skipping: [node1]
changed: [node2]

TASK [postgres_replication : copy files from master to slave] **************************************************************************************************************************
skipping: [node1]
changed: [node2]

TASK [postgres_replication : copy postgresql.conf] *************************************************************************************************************************************
skipping: [node1]
ok: [node2]

TASK [postgres_replication : copy pg_hba.conf] *****************************************************************************************************************************************
skipping: [node1]
changed: [node2]

TASK [postgres_replication : start postgresql-server on node2] *************************************************************************************************************************
skipping: [node1]
changed: [node2]

PLAY RECAP *****************************************************************************************************************************************************************************
barman                     : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=9    changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
node2                      : ok=11   changed=6    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   

user@u22ws:~/otus/hw-46/ansible$ 
```

![Скриншот выполнения плэйбука](pics/01_screenshot_ansible-playbook.png)  
+ Проверка работы репликации  
На хосте node1 в psql создадим какую-нить базу, и проверим, что она появилась на реплике   
```
СREATE DATABASE test-46;
postgres=# \l
                              List of databases
   Name    |  Owner   | Encoding | Collate |  Ctype  |   Access privileges   
-----------+----------+----------+---------+---------+-----------------------
 otus      | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 postgres  | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 template0 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 template1 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 test-46   | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
(5 rows)

```
+ Такая же база должна реплицирваться на node2  
```
postgres=# \l
                              List of databases
   Name    |  Owner   | Encoding | Collate |  Ctype  |   Access privileges   
-----------+----------+----------+---------+---------+-----------------------
 otus      | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 postgres  | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 template0 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 template1 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 test-46   | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
(5 rows)

postgres=# 
```

![Скриншот проверки репликации master-replica](pics/02_check_replication.png)

+ Нв мастере node1  
```
root@node1:~# sudo -u postgres psql
could not change directory to "/root": Permission denied
psql (14.20 (Ubuntu 14.20-0ubuntu0.22.04.1))
Type "help" for help.

postgres=# SELECT * FROM pg_stat_replication \gx
-[ RECORD 1 ]----+------------------------------
pid              | 2052
usesysid         | 16384
usename          | replicator
application_name | walreceiver
client_addr      | 192.168.57.12
client_hostname  | 
client_port      | 39816
backend_start    | 2026-01-03 13:39:06.470178-03
backend_xmin     | 753
state            | streaming
sent_lsn         | 0/9000148
write_lsn        | 0/9000148
flush_lsn        | 0/9000148
replay_lsn       | 0/9000148
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 0
sync_state       | async
reply_time       | 2026-01-03 14:20:54.93578-03

postgres=# 
    
```
![Скриншот проверки репликации](pics/03_replication_check.png)

+ На реплике node2  
```
postgres=# select * from pg_stat_wal_receiver \gx
-[ RECORD 1 ]---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
pid                   | 2014
status                | streaming
receive_start_lsn     | 0/9000000
receive_start_tli     | 1
written_lsn           | 0/9000148
flushed_lsn           | 0/9000148
received_tli          | 1
last_msg_send_time    | 2026-01-03 14:21:45.010303-03
last_msg_receipt_time | 2026-01-03 14:21:45.026282-03
latest_end_lsn        | 0/9000148
latest_end_time       | 2026-01-03 13:44:10.621998-03
slot_name             | 
sender_host           | 192.168.57.11
sender_port           | 5432
conninfo              | user=replicator password=******** channel_binding=prefer dbname=replication host=192.168.57.11 port=5432 fallback_application_name=walreceiver sslmode=prefer sslcompression=0 sslsni=1 ssl_min_protocol_version=TLSv1.2 gssencmode=prefer krbsrvname=postgres target_session_attrs=any

postgres=# 

```

##  Настройка Barman Backup  
+ Установка утилиты  

```
vagrant@barman:~$ sudo -i
root@barman:~# apt update
...
root@barman:~# apt install -y barman-cli barman postgresql
```
+ Настройка утилиты  
```
barman@barman:/root$ cd
barman@barman:~$ pwd
/var/lib/barman
barman@barman:~$ ssh-keygen -t rsa -b 4096
Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/barman/.ssh/id_rsa): 
Created directory '/var/lib/barman/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /var/lib/barman/.ssh/id_rsa
Your public key has been saved in /var/lib/barman/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:oTLtjB0G9NW5PMbAZume16pBCXXElFUAZgBDNPBHxxQ barman@barman
The key's randomart image is:
+---[RSA 4096]----+
|    o+*o=XE*oo.  |
|   . o **=*      |
|    . ++o+ .     |
|     o +.o*      |
|    o =.So o     |
|     O oo . .    |
|    . + .. .     |
|         ..      |
|        ..       |
+----[SHA256]-----+
barman@barman:~$ ls -la .ssh/
total 16
drwx------ 2 barman barman 4096 Jan  3 12:58 .
drwxr-x--- 3 barman barman 4096 Jan  3 12:58 ..
-rw------- 1 barman barman 3381 Jan  3 12:58 id_rsa
-rw-r--r-- 1 barman barman  739 Jan  3 12:58 id_rsa.pub
barman@barman:~$ nano /var/lib/barman/.ssh/authorized_keys
barman@barman:~$ cat .ssh/id_rsa.pub 
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC++iRN7yfwXlwhch3PMTdG/NeenT/CYdxfeW1SyK+z0DA3nbYmGP70AUuAPEzjWSJcX2fDcynlVeszObVv163sbxe+i9vsti30A7b7U3HWQcXTwB2n3oN0tdS6FOp+rXi+9vwBbVmciBJa/D3XgCrRgcFvAPWYpHYfva8im4bu83vgeHaRj5uD/jpyB199YX6MICwaaGzIZ7rvzxpcAgiGyq5LBdMv2CSKKpG3d+VCK/DFGVZJh9gkbIocdO/QkUUw23ir9HqpeS5rsMKujin4ucUXc7+FK7cwWODKx+Q9kaksLmbvt0Ir3aSJt7DT7vYXn5zKw8I9T2cGSHQQElgx3RQAhZ9ZVEs131IW/Srd+Wn13z822+PBKX6C+nUIQAZohOUDA/IBB1VxdHCgwy6HVC/Qmk8pEzmvng/nUdwhd2AwRZsqzFMwcb4TSICxZxTl/4oU02IfvOS3tuIWz7i2E+XOP04tuNF4DOYxzrekHHyd/EYGY5P0EK9z+DUzw4r6z5At0xtBmSlF+a9fPBfHEKyuMo3HOV1DbBj7L34DG4zAVLTU8+0P4z4xdbCpU8x8tT/ANP/E7hp3DodATKAShyn/O++w/Z08/LxVkMt6tZKEwhq+AId4JSQVxfC0Ve4aHKgySUQbW1mV3nGFgd+VMECdzfS+1vXbS8kTnVeFWw== barman@barman
barman@barman:~$ 
barman@barman:~$ 
barman@barman:~$ nano ~/.pgpass
barman@barman:~$ ls -la !$
ls -la ~/.pgpass
-rw-rw-r-- 1 barman barman 38 Jan  3 13:22 /var/lib/barman/.pgpass
barman@barman:~$ chmod 600 !$
chmod 600 ~/.pgpass
barman@barman:~$ ls -la ~/.pgpass
-rw------- 1 barman barman 38 Jan  3 13:22 /var/lib/barman/.pgpass
barman@barman:~$ psql -h 192.168.57.11 -U barman -d postgres 
psql (14.20 (Ubuntu 14.20-0ubuntu0.22.04.1))
Type "help" for help.

postgres=> \l
                              List of databases
   Name    |  Owner   | Encoding | Collate |  Ctype  |   Access privileges   
-----------+----------+----------+---------+---------+-----------------------
 otus      | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 postgres  | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
 template0 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 template1 | postgres | UTF8     | C.UTF-8 | C.UTF-8 | =c/postgres          +
           |          |          |         |         | postgres=CTc/postgres
 test-46   | postgres | UTF8     | C.UTF-8 | C.UTF-8 | 
(5 rows)

postgres=> \q
barman@barman:~$ psql -h 192.168.57.11 -U barman -c "IDENTIFY_SYSTEM" replication=1
psql: error: connection to server at "192.168.57.11", port 5432 failed: FATAL:  no pg_hba.conf entry for replication connection from host "192.168.57.13", user "barman", no encryption
barman@barman:~$ psql -h 192.168.57.11 -U barman -c "IDENTIFY_SYSTEM" replication=1
      systemid       | timeline |  xlogpos  | dbname 
---------------------+----------+-----------+--------
 7590572975049464140 |        1 | 0/3058918 | 
(1 row)

barman@barman:~$ 

```
+ Создаём файл /etc/barman.conf  
```

```

+ Проверяем доступ barman to node1 server  
```
arman@barman:~$ barman check node1
Server node1:
	WAL archive: FAILED (please make sure WAL shipping is setup)
	PostgreSQL: OK
	superuser or standard user with backup privileges: OK
	PostgreSQL streaming: OK
	wal_level: OK
	replication slot: OK
	directories: OK
	retention policy settings: OK
	backup maximum age: OK (no last_backup_maximum_age provided)
	backup minimum size: OK (0 B)
	wal maximum age: OK (no last_wal_maximum_age provided)
	wal size: OK (0 B)
	compression settings: OK
	failed backups: OK (there are 0 failed backups)
	minimum redundancy requirements: OK (have 0 backups, expected at least 0)
	pg_basebackup: OK
	pg_basebackup compatible: OK
	pg_basebackup supports tablespaces mapping: OK
	systemid coherence: OK (no system Id stored on disk)
	pg_receivexlog: OK
	pg_receivexlog compatible: OK
	receive-wal running: OK
	archiver errors: OK
barman@barman:~$ barman switch-wal node1
The WAL file 000000010000000000000004 has been closed on server 'node1'
barman@barman:~$ barman switch-wal node1
The WAL file 000000010000000000000005 has been closed on server 'node1'
barman@barman:~$ 

```
+ Избавляемся от ошибки доступа  
```
barman@barman:~$ barman switch-wal --force --archive node1
The WAL file 000000010000000000000006 has been closed on server 'node1'
Waiting for the WAL file 000000010000000000000006 from server 'node1' (max: 30 seconds)
Processing xlog segments from streaming for node1
	000000010000000000000006
barman@barman:~$ barman check node1
Server node1:
	PostgreSQL: OK
	superuser or standard user with backup privileges: OK
	PostgreSQL streaming: OK
	wal_level: OK
	replication slot: OK
	directories: OK
	retention policy settings: OK
	backup maximum age: OK (no last_backup_maximum_age provided)
	backup minimum size: OK (0 B)
	wal maximum age: OK (no last_wal_maximum_age provided)
	wal size: OK (0 B)
	compression settings: OK
	failed backups: OK (there are 0 failed backups)
	minimum redundancy requirements: OK (have 0 backups, expected at least 0)
	pg_basebackup: OK
	pg_basebackup compatible: OK
	pg_basebackup supports tablespaces mapping: OK
	systemid coherence: OK (no system Id stored on disk)
	pg_receivexlog: OK
	pg_receivexlog compatible: OK
	receive-wal running: OK
	archiver errors: OK
barman@barman:~$ 

```
![Скриншот node2 & node1](pics/04_screenshot_backup.png)
### На этом настройка бекапа завершена.  

## ДЗ-46 выполнено  
